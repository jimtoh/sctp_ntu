{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimtoh/sctp_ntu/blob/main/5m_data_2_9_Hands_on_with_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-on with Spark"
      ],
      "metadata": {
        "id": "Yf22YCkqc0Fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![spark](https://cdn-images-1.medium.com/max/300/1*c8CtvqKJDVUnMoPGujF5fA.png)"
      ],
      "metadata": {
        "id": "B96jjJtWf6Z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark is the Python API of Spark; which means it can do almost all the things python can- Machine learning (ML), exploratory data analysis (EDA), ETLs for data platform. And all of them in a distributed manner.\n",
        "\n",
        "![pyspark](https://editor.analyticsvidhya.com/uploads/20981sp3.JPG)\n",
        "\n",
        "In simple terms, each time you submit a PySpark job, the code gets internally converted into a MapReduce program and gets executed in the Java Virtual Machine. Spark also uses Lazy Evaluation, it delays its evaluation as much as it can. Each time you submit a job, spark creates an action plan for how to execute the code, and then does nothing. Finally, when you ask for the result (i.e, calls an action), it executes the plan, which is basically all the transofrmations you have mentioned in your code.\n"
      ],
      "metadata": {
        "id": "GRrcTfEGc8Z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our lesson, we will be running Spark on **local** mode.\n",
        "\n",
        "In this mode, Spark runs on a single machine, utilizing available cores (similar to Polars).\n",
        "It's useful for development, learning, testing, and debugging since everything runs on the local machine without needing a cluster.\n",
        "\n",
        "In actual production environments, Spark is usually run on a cluster of machines (YARN, Mesos or Kubernetes mode)."
      ],
      "metadata": {
        "id": "h5598w-HtOci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing and Initializing Spark\n",
        "\n",
        "First, we'll need to install Spark and its dependencies:\n",
        "\n",
        "1.   Java 8\n",
        "2.   Apache Spark with Hadoop\n",
        "3.   Findspark (used to locate the Spark in the system)\n"
      ],
      "metadata": {
        "id": "j_yU4yEjvLH7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcqaRWOj92-_"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# This link is down, need to use another mirror site\n",
        "# !wget -q https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz\n",
        "# Either retrieve from archive https://archive.apache.org/dist/spark/spark-3.5.5/ or from latest https://spark.apache.org/downloads.html\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.6-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the files in the current directory:"
      ],
      "metadata": {
        "id": "3KGG8iyLvZHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxIVqI4XYI0_",
        "outputId": "bf385c7f-fb84-4530-fd02-5a72be82abd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\t\t spark-3.5.6-bin-hadoop3.tgz\n",
            "spark-3.5.6-bin-hadoop3  spark-3.5.6-bin-hadoop3.tgz.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Print* the current directory:"
      ],
      "metadata": {
        "id": "rupTwiHzvcLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d94vMnN4ad2C",
        "outputId": "550d9fd9-f218-46a5-e403-3079cdc44b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the OS Environment Variables so that Findspark can locate Spark in the system:"
      ],
      "metadata": {
        "id": "n2mYe6MgvtNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.5-bin-hadoop3\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.6-bin-hadoop3\""
      ],
      "metadata": {
        "id": "CYRAXXp8aKMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "9IVFrHAAabLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "Nc9T58Y2as5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoking `spark` will print the SparkContext"
      ],
      "metadata": {
        "id": "OFuPn8O_wWRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "TwirdxMKv-ie",
        "outputId": "bbe45d15-7468-47ae-b34d-3308f2618cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7eec8790c5d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://be5f1c37d6cc:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.6</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark SQL and DataFrames\n",
        "\n",
        "Spark SQL and DataFrames are higher-level modules of Apache Spark, they work together to make data processing with Spark more intuitive and optimized, especially for those who come from an SQL or data analytics background.\n",
        "\n",
        "- **SQL Interface to Spark**: Spark SQL lets users execute SQL queries alongside Spark programs.\n",
        "\n",
        "- **DataFrames are abstraction over RDDs**: A DataFrame is a distributed collection of data organized into named columns. Conceptually, it's equivalent to a table in a relational database or a data frame in R or Python, but with optimizations for distributed processing and scalability. While RDD (Resilient Distributed Dataset) is a fundamental data structure in Spark, DataFrames provide a higher-level abstraction that is often easier to use and more optimized for many tasks."
      ],
      "metadata": {
        "id": "vlvH2gCppT3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataFrame Creation"
      ],
      "metadata": {
        "id": "mL9FT69RtlhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "from pyspark.sql import Row"
      ],
      "metadata": {
        "id": "Csj4V7SebG3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([\n",
        "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
        "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
        "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
        "])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUTCVOCMbZHs",
        "outputId": "352cf986-5a17-4067-8524-12c270137a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark infers the DataFrame schema (dtypes) by taking a sample from the data (just like Pandas)"
      ],
      "metadata": {
        "id": "o3pCzfH8t85j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM049Yg3bfei",
        "outputId": "4de00b5b-12cd-452a-d85a-c0170ed9eee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
            "|  4|5.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You can also pass an explicit schema:"
      ],
      "metadata": {
        "id": "hDh6bDwPuHuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
        "], schema='a long, b double, c string, d date, e timestamp')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPIuxbgVuJ7L",
        "outputId": "54d568e6-81d7-4394-eb64-88ff4818dec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark DataFrame is lazily evaluated and invoking `df` does not trigger the computation and show anything. You need to explicitly call the `show` method:"
      ],
      "metadata": {
        "id": "gELgm_S3NGbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WztTVjujuRsj",
        "outputId": "9622599a-dca0-440b-a262-1452ed3d2abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
            "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n",
            "root\n",
            " |-- a: long (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- c: string (nullable = true)\n",
            " |-- d: date (nullable = true)\n",
            " |-- e: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Data In/Out\n",
        "\n",
        "There are many data sources available in PySpark such as CSV, Parquet, ORC, JDBC, text, Avro, etc.\n",
        "\n",
        "First, let's download the files in various format from GCS, data which we explored in Unit 2.3 and 2.8."
      ],
      "metadata": {
        "id": "7l6zXe8wujkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data"
      ],
      "metadata": {
        "id": "r2TEii0S7_JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P data https://storage.googleapis.com/su-artifacts/movies_metadata.csv\n",
        "!wget -P data https://storage.googleapis.com/su-artifacts/ratings.csv\n",
        "!wget -P data https://storage.googleapis.com/su-artifacts/taxi_trip_data.csv\n",
        "!wget -P data https://storage.googleapis.com/su-artifacts/userdata1.orc\n",
        "!wget -P data https://storage.googleapis.com/su-artifacts/userdata1.parquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrUfmub78XZR",
        "outputId": "55f2ef78-51cc-4503-e94a-646baf16ba3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-10 01:06:11--  https://storage.googleapis.com/su-artifacts/movies_metadata.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.0.91, 172.217.12.27, 142.250.65.123, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.0.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34445126 (33M) [text/csv]\n",
            "Saving to: ‘data/movies_metadata.csv’\n",
            "\n",
            "movies_metadata.csv 100%[===================>]  32.85M  11.5MB/s    in 2.9s    \n",
            "\n",
            "2025-06-10 01:06:16 (11.5 MB/s) - ‘data/movies_metadata.csv’ saved [34445126/34445126]\n",
            "\n",
            "--2025-06-10 01:06:16--  https://storage.googleapis.com/su-artifacts/ratings.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.0.91, 172.217.12.27, 142.250.65.123, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.0.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 709550327 (677M) [text/csv]\n",
            "Saving to: ‘data/ratings.csv’\n",
            "\n",
            "ratings.csv         100%[===================>] 676.68M  19.7MB/s    in 35s     \n",
            "\n",
            "2025-06-10 01:06:53 (19.1 MB/s) - ‘data/ratings.csv’ saved [709550327/709550327]\n",
            "\n",
            "--2025-06-10 01:06:53--  https://storage.googleapis.com/su-artifacts/taxi_trip_data.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.0.91, 172.217.12.27, 142.250.65.123, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.0.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1466182802 (1.4G) [text/csv]\n",
            "Saving to: ‘data/taxi_trip_data.csv’\n",
            "\n",
            "taxi_trip_data.csv  100%[===================>]   1.37G  19.5MB/s    in 72s     \n",
            "\n",
            "2025-06-10 01:08:06 (19.3 MB/s) - ‘data/taxi_trip_data.csv’ saved [1466182802/1466182802]\n",
            "\n",
            "--2025-06-10 01:08:06--  https://storage.googleapis.com/su-artifacts/userdata1.orc\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.7.59, 172.217.12.27, 142.250.65.123, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.7.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46545 (45K) [application/octet-stream]\n",
            "Saving to: ‘data/userdata1.orc’\n",
            "\n",
            "userdata1.orc       100%[===================>]  45.45K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-06-10 01:08:08 (1.10 MB/s) - ‘data/userdata1.orc’ saved [46545/46545]\n",
            "\n",
            "--2025-06-10 01:08:08--  https://storage.googleapis.com/su-artifacts/userdata1.parquet\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.7.59, 172.217.12.27, 142.250.65.123, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.7.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113629 (111K) [application/octet-stream]\n",
            "Saving to: ‘data/userdata1.parquet’\n",
            "\n",
            "userdata1.parquet   100%[===================>] 110.97K   242KB/s    in 0.5s    \n",
            "\n",
            "2025-06-10 01:08:10 (242 KB/s) - ‘data/userdata1.parquet’ saved [113629/113629]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_zUlgQ4cILE",
        "outputId": "2e384389-fea4-405d-d97c-76dc0276fa80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movies_metadata.csv  taxi_trip_data.csv  userdata1.parquet\n",
            "ratings.csv\t     userdata1.orc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.parquet('data/userdata1.parquet')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5odksbT69b2J",
        "outputId": "ad87b231-f412-4bf5-fc9f-068d06bed3e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+---+----------+---------+--------------------+------+---------------+-------------------+--------------------+----------+---------+--------------------+--------------------+\n",
            "|  registration_dttm| id|first_name|last_name|               email|gender|     ip_address|                 cc|             country| birthdate|   salary|               title|            comments|\n",
            "+-------------------+---+----------+---------+--------------------+------+---------------+-------------------+--------------------+----------+---------+--------------------+--------------------+\n",
            "|2016-02-03 07:55:29|  1|    Amanda|   Jordan|    ajordan0@com.com|Female|    1.197.201.2|   6759521864920116|           Indonesia|  3/8/1971| 49756.53|    Internal Auditor|               1E+02|\n",
            "|2016-02-03 17:04:03|  2|    Albert|  Freeman|     afreeman1@is.gd|  Male| 218.111.175.34|                   |              Canada| 1/16/1968|150280.17|       Accountant IV|                    |\n",
            "|2016-02-03 01:09:31|  3|    Evelyn|   Morgan|emorgan2@altervis...|Female|   7.161.136.94|   6767119071901597|              Russia|  2/1/1960|144972.51| Structural Engineer|                    |\n",
            "|2016-02-03 00:36:21|  4|    Denise|    Riley|    driley3@gmpg.org|Female|  140.35.109.83|   3576031598965625|               China|  4/8/1997| 90263.05|Senior Cost Accou...|                    |\n",
            "|2016-02-03 05:05:31|  5|    Carlos|    Burns|cburns4@miitbeian...|      | 169.113.235.40|   5602256255204850|        South Africa|          |     NULL|                    |                    |\n",
            "|2016-02-03 07:22:34|  6|   Kathryn|    White|  kwhite5@google.com|Female| 195.131.81.179|   3583136326049310|           Indonesia| 2/25/1983| 69227.11|   Account Executive|                    |\n",
            "|2016-02-03 08:33:08|  7|    Samuel|   Holmes|sholmes6@foxnews.com|  Male| 232.234.81.197|   3582641366974690|            Portugal|12/18/1987| 14247.62|Senior Financial ...|                    |\n",
            "|2016-02-03 06:47:06|  8|     Harry|   Howell| hhowell7@eepurl.com|  Male|   91.235.51.73|                   |Bosnia and Herzeg...|  3/1/1962|186469.43|    Web Developer IV|                    |\n",
            "|2016-02-03 03:52:53|  9|      Jose|   Foster|   jfoster8@yelp.com|  Male|   132.31.53.61|                   |         South Korea| 3/27/1992|231067.84|Software Test Eng...|               1E+02|\n",
            "|2016-02-03 18:29:47| 10|     Emily|  Stewart|estewart9@opensou...|Female| 143.28.251.245|   3574254110301671|             Nigeria| 1/28/1997| 27234.28|     Health Coach IV|                    |\n",
            "|2016-02-03 00:10:42| 11|     Susan|  Perkins| sperkinsa@patch.com|Female|    180.85.0.62|   3573823609854134|              Russia|          |210001.95|                    |                    |\n",
            "|2016-02-03 18:04:34| 12|     Alice|    Berry|aberryb@wikipedia...|Female| 246.225.12.189|   4917830851454417|               China| 8/12/1968| 22944.53|    Quality Engineer|                    |\n",
            "|2016-02-03 18:48:17| 13|    Justin|    Berry|jberryc@usatoday.com|  Male|   157.7.146.43|6331109912871813274|              Zambia| 8/15/1975| 44165.46|Structural Analys...|                    |\n",
            "|2016-02-03 21:46:52| 14|     Kathy| Reynolds|kreynoldsd@redcro...|Female|  81.254.172.13|   5537178462965976|Bosnia and Herzeg...| 6/27/1970|286592.99|           Librarian|                    |\n",
            "|2016-02-03 08:53:23| 15|   Dorothy|   Hudson|dhudsone@blogger.com|Female|       8.59.7.0|   3542586858224170|               Japan|12/20/1989|157099.71|  Nurse Practicioner|<script>alert('hi...|\n",
            "|2016-02-03 00:44:01| 16|     Bruce|   Willis|bwillisf@bluehost...|  Male|239.182.219.189|   3573030625927601|              Brazil|          |239100.65|                    |                    |\n",
            "|2016-02-03 00:57:45| 17|     Emily|  Andrews|eandrewsg@cornell...|Female| 29.231.180.172|     30271790537626|              Russia| 4/13/1990|116800.65|        Food Chemist|                    |\n",
            "|2016-02-03 16:44:24| 18|   Stephen|  Wallace|swallaceh@netvibe...|  Male|  152.49.213.62|   5433943468526428|             Ukraine| 1/15/1978|248877.99|Account Represent...|                    |\n",
            "|2016-02-03 11:45:54| 19|  Clarence|   Lawson|clawsoni@vkontakt...|  Male| 107.175.15.152|   3544052814080964|              Russia|          |177122.99|                    |                    |\n",
            "|2016-02-03 10:30:36| 20|   Rebecca|     Bell| rbellj@bandcamp.com|Female|172.215.104.127|                   |               China|          |137251.19|                    |                    |\n",
            "+-------------------+---+----------+---------+--------------------+------+---------------+-------------------+--------------------+----------+---------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.orc('data/userdata1.orc')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I37la4QA-TMm",
        "outputId": "29ec9b33-7eca-4037-fade-d9c20d25a589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+--------+---------+--------------------+------+---------------+----------------+--------------------+----------+---------+--------------------+------+\n",
            "|              _col0|_col1|   _col2|    _col3|               _col4| _col5|          _col6|           _col7|               _col8|     _col9|   _col10|              _col11|_col12|\n",
            "+-------------------+-----+--------+---------+--------------------+------+---------------+----------------+--------------------+----------+---------+--------------------+------+\n",
            "|2016-02-03 13:36:39|    1|  Donald|    Lewis|dlewis0@clickbank...|  Male|  102.22.124.20|                |           Indonesia|  7/9/1972|140249.37|Senior Financial ...|      |\n",
            "|2016-02-03 00:22:28|    2|  Walter|  Collins|wcollins1@bloglov...|  Male|   247.28.26.93|3587726269478025|               China|          |     NULL|                    |      |\n",
            "|2016-02-03 18:29:04|    3|Michelle|Henderson|mhenderson2@geoci...|Female| 193.68.146.150|                |              France| 1/15/1964|236219.26|             Teacher|      |\n",
            "|2016-02-03 13:42:19|    4|    Lori|   Hudson| lhudson3@dion.ne.jp|      |  34.252.168.48|3568840151595649|              Russia| 4/22/1988|     NULL|Nuclear Power Eng...|      |\n",
            "|2016-02-03 00:15:29|    5|  Howard|   Miller|   hmiller4@fema.gov|  Male|103.193.150.230|3583473261055014|              France|11/26/1998| 50210.02|       Senior Editor|      |\n",
            "|2016-02-03 10:49:07|    6| Frances|    Adams|fadams5@123-reg.c...|Female| 106.196.106.93|                |              Russia| 3/27/1997| 82175.77| Account Coordinator|      |\n",
            "|2016-02-03 19:44:12| NULL|  Steven|   Hanson|  shanson6@cisco.com|  Male|234.130.172.185|3550842607768119|           Indonesia|          |129582.61|                    |      |\n",
            "|2016-02-03 08:11:34|    8|   Louis|  Simmons|   lsimmons7@icio.us|  Male|    18.69.80.15|                |               China|  6/1/1992| 90744.86|    Product Engineer|      |\n",
            "|2016-02-03 23:56:51|    9|   Keith|   Parker|kparker8@amazonaw...|  Male|  108.205.40.64|                |          Guadeloupe|12/30/1992|  60618.9|        Developer II|      |\n",
            "|2016-02-03 07:47:29|   10|   Wanda|   Walker|wwalker9@latimes.com|Female|  246.214.98.78|3539421569669478|            Portugal|          |137664.53|                    |      |\n",
            "|2016-02-03 16:39:23|   11| Kathryn|   Weaver|kweavera@bizjourn...|Female| 157.237.161.75| 201425019338900|              Sweden|          |117572.65|                    |      |\n",
            "|2016-02-03 06:50:56|   12|  Philip|     Ward| pwardb@sakura.ne.jp|  Male|  77.140.225.69| 201508031789224|              Greece|  9/3/1984|238925.79|Human Resources M...|      |\n",
            "|2016-02-03 23:36:58|   13|  Evelyn|   Harvey|   eharveyc@time.com|      |  254.174.154.7|3539535868968594|               China| 5/15/1979|     NULL|Software Engineer...|      |\n",
            "|2016-02-03 07:33:24|   14|  Andrea|     Lane|       alaned@gov.uk|Female|192.253.116.192|5100174455306952|           Indonesia| 1/19/1989|166778.42|            Operator|      |\n",
            "|2016-02-03 13:45:04|   15|   Bobby|  Vasquez|  bvasqueze@furl.net|  Male|  126.60.18.195|3581051861650673|         Philippines| 1/25/1975|138184.83|       Senior Editor|      |\n",
            "|2016-02-03 21:58:10|   16| Kenneth|   Gibson|kgibsonf@soundclo...|  Male| 91.153.142.170|5389947292571488|                Peru| 11/3/1975| 98614.53|  Environmental Tech|      |\n",
            "|2016-02-03 16:22:34|   17|   Emily|     Hill|    ehillg@house.gov|Female|109.107.174.205|                |Palestinian Terri...| 5/18/1956|218781.48| Executive Secretary|      |\n",
            "|2016-02-03 23:20:49|   18|   Kelly|   Fowler|   kfowlerh@dell.com|Female|  147.58.88.116|3551741291105936|              Greece| 6/11/1975|117249.56|Systems Administr...|      |\n",
            "|2016-02-03 18:28:46|   19|   Diana|   Howell| dhowelli@sphinn.com|Female|   21.240.75.42|4026635872860296|                Iran|  7/7/1993|174844.52|             Teacher|      |\n",
            "|2016-02-03 02:23:26|   20|  Johnny|  Collins| jcollinsj@google.ca|  Male| 38.173.129.250| 372301677387203|         Afghanistan| 7/28/1987|155908.69|       Social Worker|      |\n",
            "+-------------------+-----+--------+---------+--------------------+------+---------------+----------------+--------------------+----------+---------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies = spark.read.csv('data/movies_metadata.csv', header=True)\n",
        "ratings = spark.read.csv('data/ratings.csv', header=True)\n",
        "taxi = spark.read.csv('data/taxi_trip_data.csv', header=True)"
      ],
      "metadata": {
        "id": "miuJSiRD_eA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbw45ZcZ_4Bn",
        "outputId": "288ed543-c039-4015-f1e7-fc820013253c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- adult: string (nullable = true)\n",
            " |-- belongs_to_collection: string (nullable = true)\n",
            " |-- budget: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- homepage: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- imdb_id: string (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: string (nullable = true)\n",
            " |-- poster_path: string (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- release_date: string (nullable = true)\n",
            " |-- revenue: string (nullable = true)\n",
            " |-- runtime: string (nullable = true)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- tagline: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- video: string (nullable = true)\n",
            " |-- vote_average: string (nullable = true)\n",
            " |-- vote_count: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz0jjCFO_wcU",
        "outputId": "42a14ac3-fde5-438c-bf5b-bec53ad71284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: string (nullable = true)\n",
            " |-- movieId: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC-BED54G3lF",
        "outputId": "72bed946-e9a9-428b-eb82-eda0f6673a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- vendor_id: string (nullable = true)\n",
            " |-- pickup_datetime: string (nullable = true)\n",
            " |-- dropoff_datetime: string (nullable = true)\n",
            " |-- passenger_count: string (nullable = true)\n",
            " |-- trip_distance: string (nullable = true)\n",
            " |-- rate_code: string (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- payment_type: string (nullable = true)\n",
            " |-- fare_amount: string (nullable = true)\n",
            " |-- extra: string (nullable = true)\n",
            " |-- mta_tax: string (nullable = true)\n",
            " |-- tip_amount: string (nullable = true)\n",
            " |-- tolls_amount: string (nullable = true)\n",
            " |-- imp_surcharge: string (nullable = true)\n",
            " |-- total_amount: string (nullable = true)\n",
            " |-- pickup_location_id: string (nullable = true)\n",
            " |-- dropoff_location_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies = spark.read.csv('data/movies_metadata.csv', header=True, inferSchema=True, quote=\"\\\"\", escape=\"\\\"\")"
      ],
      "metadata": {
        "id": "IWec2yxrG7yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgVmnJFdG_Et",
        "outputId": "0629645d-2e05-45ad-8c97-e5e7f87d0c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- adult: string (nullable = true)\n",
            " |-- belongs_to_collection: string (nullable = true)\n",
            " |-- budget: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- homepage: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- imdb_id: string (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: string (nullable = true)\n",
            " |-- poster_path: string (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- release_date: string (nullable = true)\n",
            " |-- revenue: string (nullable = true)\n",
            " |-- runtime: string (nullable = true)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- tagline: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- video: string (nullable = true)\n",
            " |-- vote_average: string (nullable = true)\n",
            " |-- vote_count: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = spark.read.csv('data/ratings.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "rxXMe5tdAhhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmfe5kwUArq-",
        "outputId": "bc49aa91-0851-4b7a-950f-f46d7ad5cf30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing a schema will speed up the read."
      ],
      "metadata": {
        "id": "9a3R2ZE1HUFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtypes = ['vendor_id integer',\n",
        " 'pickup_datetime timestamp',\n",
        " 'dropoff_datetime timestamp',\n",
        " 'passenger_count integer',\n",
        " 'trip_distance double',\n",
        " 'rate_code integer',\n",
        " 'store_and_fwd_flag string',\n",
        " 'payment_type integer',\n",
        " 'fare_amount double',\n",
        " 'extra double',\n",
        " 'mta_tax double',\n",
        " 'tip_amount double',\n",
        " 'tolls_amount double',\n",
        " 'imp_surcharge double',\n",
        " 'total_amount double',\n",
        " 'pickup_location_id integer',\n",
        " 'dropoff_location_id integer']"
      ],
      "metadata": {
        "id": "1OuIC8ObHy0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi = spark.read.csv('data/taxi_trip_data.csv', header=True,\n",
        "                      schema=', '.join(dtypes))"
      ],
      "metadata": {
        "id": "5JbmrKbiHKdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEuzBCPRAFMY",
        "outputId": "fa277ca4-cdcf-433a-99b9-b33519f55861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- vendor_id: integer (nullable = true)\n",
            " |-- pickup_datetime: timestamp (nullable = true)\n",
            " |-- dropoff_datetime: timestamp (nullable = true)\n",
            " |-- passenger_count: integer (nullable = true)\n",
            " |-- trip_distance: double (nullable = true)\n",
            " |-- rate_code: integer (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- payment_type: integer (nullable = true)\n",
            " |-- fare_amount: double (nullable = true)\n",
            " |-- extra: double (nullable = true)\n",
            " |-- mta_tax: double (nullable = true)\n",
            " |-- tip_amount: double (nullable = true)\n",
            " |-- tolls_amount: double (nullable = true)\n",
            " |-- imp_surcharge: double (nullable = true)\n",
            " |-- total_amount: double (nullable = true)\n",
            " |-- pickup_location_id: integer (nullable = true)\n",
            " |-- dropoff_location_id: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a couple of ways to view your dataframe in PySpark:\n",
        "\n",
        "1.   `df.take(5)` will return a list of five Row objects.\n",
        "2.   `df.collect()` will get all of the data from the entire DataFrame. Be really careful when using it, because if you have a large data set, you can easily crash the driver node.\n",
        "3.   `df.show()` is the most commonly used method to view a dataframe. There are a few parameters we can pass to this method, like the number of rows and truncaiton. For example, `df.show(5, False)` or ` df.show(5, truncate=False)` will show the entire data wihtout any truncation.\n",
        "4.   `df.limit(5)` will **return a new DataFrame** by taking the first n rows. As spark is distributed in nature, there is no guarantee that `df.limit()` will give you the same results each time."
      ],
      "metadata": {
        "id": "DhNpGCZHI5Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vYO64dNIoYD",
        "outputId": "702cb163-8d8d-4000-d9e8-b0d3598deeec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------------+--------+--------------------+--------------------+-----+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+---------+-------+--------------------+--------+--------------------+--------------------+-----+------------+----------+\n",
            "|adult|belongs_to_collection|  budget|              genres|            homepage|   id|  imdb_id|original_language|      original_title|            overview|popularity|         poster_path|production_companies|production_countries|release_date|  revenue|runtime|    spoken_languages|  status|             tagline|               title|video|vote_average|vote_count|\n",
            "+-----+---------------------+--------+--------------------+--------------------+-----+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+---------+-------+--------------------+--------+--------------------+--------------------+-----+------------+----------+\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|  862|tt0114709|               en|           Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|   81.0|[{'iso_639_1': 'e...|Released|                NULL|           Toy Story|False|         7.7|      5415|\n",
            "|False|                 NULL|65000000|[{'id': 12, 'name...|                NULL| 8844|tt0113497|               en|             Jumanji|When siblings Jud...| 17.015539|/vzmL6fP7aPKNKPRT...|[{'name': 'TriSta...|[{'iso_3166_1': '...|  1995-12-15|262797249|  104.0|[{'iso_639_1': 'e...|Released|Roll the dice and...|             Jumanji|False|         6.9|      2413|\n",
            "|False| {'id': 119050, 'n...|       0|[{'id': 10749, 'n...|                NULL|15602|tt0113228|               en|    Grumpier Old Men|A family wedding ...|   11.7129|/6ksm1sjKMFLbO7UY...|[{'name': 'Warner...|[{'iso_3166_1': '...|  1995-12-22|        0|  101.0|[{'iso_639_1': 'e...|Released|Still Yelling. St...|    Grumpier Old Men|False|         6.5|        92|\n",
            "|False|                 NULL|16000000|[{'id': 35, 'name...|                NULL|31357|tt0114885|               en|   Waiting to Exhale|Cheated on, mistr...|  3.859495|/16XOMpEaLWkrcPqS...|[{'name': 'Twenti...|[{'iso_3166_1': '...|  1995-12-22| 81452156|  127.0|[{'iso_639_1': 'e...|Released|Friends are the p...|   Waiting to Exhale|False|         6.1|        34|\n",
            "|False| {'id': 96871, 'na...|       0|[{'id': 35, 'name...|                NULL|11862|tt0113041|               en|Father of the Bri...|Just when George ...|  8.387519|/e64sOI48hQXyru7n...|[{'name': 'Sandol...|[{'iso_3166_1': '...|  1995-02-10| 76578911|  106.0|[{'iso_639_1': 'e...|Released|Just When His Wor...|Father of the Bri...|False|         5.7|       173|\n",
            "|False|                 NULL|60000000|[{'id': 28, 'name...|                NULL|  949|tt0113277|               en|                Heat|Obsessive master ...| 17.924927|/zMyfPUelumio3tiD...|[{'name': 'Regenc...|[{'iso_3166_1': '...|  1995-12-15|187436818|  170.0|[{'iso_639_1': 'e...|Released|A Los Angeles Cri...|                Heat|False|         7.7|      1886|\n",
            "|False|                 NULL|58000000|[{'id': 35, 'name...|                NULL|11860|tt0114319|               en|             Sabrina|An ugly duckling ...|  6.677277|/jQh15y5YB7bWz1Nt...|[{'name': 'Paramo...|[{'iso_3166_1': '...|  1995-12-15|        0|  127.0|[{'iso_639_1': 'f...|Released|You are cordially...|             Sabrina|False|         6.2|       141|\n",
            "|False|                 NULL|       0|[{'id': 28, 'name...|                NULL|45325|tt0112302|               en|        Tom and Huck|A mischievous you...|  2.561161|/sGO5Qa55p7wTu7FJ...|[{'name': 'Walt D...|[{'iso_3166_1': '...|  1995-12-22|        0|   97.0|[{'iso_639_1': 'e...|Released|The Original Bad ...|        Tom and Huck|False|         5.4|        45|\n",
            "|False|                 NULL|35000000|[{'id': 28, 'name...|                NULL| 9091|tt0114576|               en|        Sudden Death|International act...|   5.23158|/eoWvKD60lT95Ss1M...|[{'name': 'Univer...|[{'iso_3166_1': '...|  1995-12-22| 64350171|  106.0|[{'iso_639_1': 'e...|Released|Terror goes into ...|        Sudden Death|False|         5.5|       174|\n",
            "|False| {'id': 645, 'name...|58000000|[{'id': 12, 'name...|http://www.mgm.co...|  710|tt0113189|               en|           GoldenEye|James Bond must u...| 14.686036|/5c0ovjT41KnYIHYu...|[{'name': 'United...|[{'iso_3166_1': '...|  1995-11-16|352194034|  130.0|[{'iso_639_1': 'e...|Released|No limits. No fea...|           GoldenEye|False|         6.6|      1194|\n",
            "+-----+---------------------+--------+--------------------+--------------------+-----+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+---------+-------+--------------------+--------+--------------------+--------------------+-----+------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku5Ohaa6JAa7",
        "outputId": "f5186b17-01df-47b7-f3ee-a931c9bda15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------------------------------------------+------------------------------------+-----+---------+-----------------+---------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------+------------+---------+-------+---------------------------------------------------------------------------------+--------+------------------------------------------------------------------------------+---------------------------+-----+------------+----------+\n",
            "|adult|belongs_to_collection                                                                                                                                          |budget  |genres                                                                                           |homepage                            |id   |imdb_id  |original_language|original_title             |overview                                                                                                                                                                                                                                                                                                                                                                                                   |popularity|poster_path                     |production_companies                                                                                                               |production_countries                                      |release_date|revenue  |runtime|spoken_languages                                                                 |status  |tagline                                                                       |title                      |video|vote_average|vote_count|\n",
            "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------------------------------------------+------------------------------------+-----+---------+-----------------+---------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------+------------+---------+-------+---------------------------------------------------------------------------------+--------+------------------------------------------------------------------------------+---------------------------+-----+------------+----------+\n",
            "|False|{'id': 10194, 'name': 'Toy Story Collection', 'poster_path': '/7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg', 'backdrop_path': '/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg'}          |30000000|[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}] |http://toystory.disney.com/toy-story|862  |tt0114709|en               |Toy Story                  |Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.                                                                                            |21.946943 |/rhIRbceoE9lR4veEXuwCC2wARtG.jpg|[{'name': 'Pixar Animation Studios', 'id': 3}]                                                                                     |[{'iso_3166_1': 'US', 'name': 'United States of America'}]|1995-10-30  |373554033|81.0   |[{'iso_639_1': 'en', 'name': 'English'}]                                         |Released|NULL                                                                          |Toy Story                  |False|7.7         |5415      |\n",
            "|False|NULL                                                                                                                                                           |65000000|[{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10751, 'name': 'Family'}]|NULL                                |8844 |tt0113497|en               |Jumanji                    |When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.|17.015539 |/vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg|[{'name': 'TriStar Pictures', 'id': 559}, {'name': 'Teitler Film', 'id': 2550}, {'name': 'Interscope Communications', 'id': 10201}]|[{'iso_3166_1': 'US', 'name': 'United States of America'}]|1995-12-15  |262797249|104.0  |[{'iso_639_1': 'en', 'name': 'English'}, {'iso_639_1': 'fr', 'name': 'Français'}]|Released|Roll the dice and unleash the excitement!                                     |Jumanji                    |False|6.9         |2413      |\n",
            "|False|{'id': 119050, 'name': 'Grumpy Old Men Collection', 'poster_path': '/nLvUdqgPgm3F85NMCii9gVFUcet.jpg', 'backdrop_path': '/hypTnLot2z8wpFS7qwsQHW1uV8u.jpg'}    |0       |[{'id': 10749, 'name': 'Romance'}, {'id': 35, 'name': 'Comedy'}]                                 |NULL                                |15602|tt0113228|en               |Grumpier Old Men           |A family wedding reignites the ancient feud between next-door neighbors and fishing buddies John and Max. Meanwhile, a sultry Italian divorcée opens a restaurant at the local bait shop, alarming the locals who worry she'll scare the fish away. But she's less interested in seafood than she is in cooking up a hot time with Max.                                                                    |11.7129   |/6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg|[{'name': 'Warner Bros.', 'id': 6194}, {'name': 'Lancaster Gate', 'id': 19464}]                                                    |[{'iso_3166_1': 'US', 'name': 'United States of America'}]|1995-12-22  |0        |101.0  |[{'iso_639_1': 'en', 'name': 'English'}]                                         |Released|Still Yelling. Still Fighting. Still Ready for Love.                          |Grumpier Old Men           |False|6.5         |92        |\n",
            "|False|NULL                                                                                                                                                           |16000000|[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]    |NULL                                |31357|tt0114885|en               |Waiting to Exhale          |Cheated on, mistreated and stepped on, the women are holding their breath, waiting for the elusive \"good man\" to break a string of less-than-stellar lovers. Friends and confidants Vannah, Bernie, Glo and Robin talk it all out, determined to find a better way to breathe.                                                                                                                             |3.859495  |/16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg|[{'name': 'Twentieth Century Fox Film Corporation', 'id': 306}]                                                                    |[{'iso_3166_1': 'US', 'name': 'United States of America'}]|1995-12-22  |81452156 |127.0  |[{'iso_639_1': 'en', 'name': 'English'}]                                         |Released|Friends are the people who let you be yourself... and never let you forget it.|Waiting to Exhale          |False|6.1         |34        |\n",
            "|False|{'id': 96871, 'name': 'Father of the Bride Collection', 'poster_path': '/nts4iOmNnq7GNicycMJ9pSAn204.jpg', 'backdrop_path': '/7qwE57OVZmMJChBpLEbJEmzUydk.jpg'}|0       |[{'id': 35, 'name': 'Comedy'}]                                                                   |NULL                                |11862|tt0113041|en               |Father of the Bride Part II|Just when George Banks has recovered from his daughter's wedding, he receives the news that she's pregnant ... and that George's wife, Nina, is expecting too. He was planning on selling their home, but that's a plan that -- like George -- will have to change with the arrival of both a grandchild and a kid of his own.                                                                             |8.387519  |/e64sOI48hQXyru7naBFyssKFxVd.jpg|[{'name': 'Sandollar Productions', 'id': 5842}, {'name': 'Touchstone Pictures', 'id': 9195}]                                       |[{'iso_3166_1': 'US', 'name': 'United States of America'}]|1995-02-10  |76578911 |106.0  |[{'iso_639_1': 'en', 'name': 'English'}]                                         |Released|Just When His World Is Back To Normal... He's In For The Surprise Of His Life!|Father of the Bride Part II|False|5.7         |173       |\n",
            "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------------------------------------------+------------------------------------+-----+---------+-----------------+---------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------+------------+---------+-------+---------------------------------------------------------------------------------+--------+------------------------------------------------------------------------------+---------------------------+-----+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can also be shown vertically\n",
        "movies.show(1, vertical=True, truncate=False)"
      ],
      "metadata": {
        "id": "sj1hzCXZKCHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.show(10)"
      ],
      "metadata": {
        "id": "WiqfEY-1Ir0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.show(10)"
      ],
      "metadata": {
        "id": "SRXESwE4Itf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.limit(5).show()"
      ],
      "metadata": {
        "id": "aG5UlLVLIypN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.describe().show()"
      ],
      "metadata": {
        "id": "uYinFUS3KXYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.describe().show()"
      ],
      "metadata": {
        "id": "xT1dm9WRKmHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.describe().show()"
      ],
      "metadata": {
        "id": "OUmLPl3LKnDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataFrame Operations on Columns\n",
        "\n",
        "We will go over the following in this section:\n",
        "\n",
        "1.   Selecting a Column\n",
        "2.   Selecting Multiple Columns\n",
        "3.   Adding New Columns\n",
        "4.   Renaming Columns\n",
        "5.   Removing Columns\n"
      ],
      "metadata": {
        "id": "srqwAMFMJkU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies.id"
      ],
      "metadata": {
        "id": "TF0Z0RqeJjp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like DataFrame, selecting a column is lazily evaluated and does not trigger the computation but returns a `Column` instance.\n",
        "\n",
        "It can be used to select columns and returns another DataFrame:"
      ],
      "metadata": {
        "id": "o59d97i2NnKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies.select(movies.id).show()"
      ],
      "metadata": {
        "id": "Ydr4uqznNl4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.select(movies.title, movies.overview).show(truncate=False)"
      ],
      "metadata": {
        "id": "G5yp1kdgOPRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a new column:"
      ],
      "metadata": {
        "id": "gqApk2x-OpEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit"
      ],
      "metadata": {
        "id": "6mf9kBX5PQaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lit means literal. It populates the row with the literal value given\n",
        "ratings.withColumn('review', lit('Great movie!')).show(10)"
      ],
      "metadata": {
        "id": "pKxyOHWFPSHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.withColumn('review', lit('Great movie!')) \\\n",
        "       .withColumn('mood', lit(5)) \\\n",
        "       .show(10)"
      ],
      "metadata": {
        "id": "itZlHm53Plh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.withColumnRenamed('overview', 'summary').show(5)"
      ],
      "metadata": {
        "id": "hUdFHvWkOlfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.drop('timestamp').show()"
      ],
      "metadata": {
        "id": "dqLqpHphQ-l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Transformation Functions"
      ],
      "metadata": {
        "id": "ECtIeRoxSdAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions available in PySpark\n",
        "from pyspark.sql import functions\n",
        "# We can use the dir function to view the available functions\n",
        "print(dir(functions))"
      ],
      "metadata": {
        "id": "a_OmdwOOSm60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "String functions:"
      ],
      "metadata": {
        "id": "d4gsChVFXOHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import concat, lower, upper, substring"
      ],
      "metadata": {
        "id": "SY96OEMERHt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.show(5)"
      ],
      "metadata": {
        "id": "EAeEaV9WS81k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.select(movies.title, movies.tagline, upper(movies.title), lower(movies.tagline),\n",
        "              substring(movies.overview, 1, 10),\n",
        "              concat(movies.title, lit(' Part 1')).alias('new_title')\n",
        "              ).show()"
      ],
      "metadata": {
        "id": "oRP7Qr0WWZZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numeric functions:"
      ],
      "metadata": {
        "id": "mzltd7IMXQ0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean, max, round"
      ],
      "metadata": {
        "id": "oxGJmZqYXQW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.select(mean(ratings.rating), max(ratings.rating)).show()"
      ],
      "metadata": {
        "id": "IRDNP5cbXnls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.withColumn('new_rating', round(ratings.rating)).show()"
      ],
      "metadata": {
        "id": "4YjWCWIIX01h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date/time functions:"
      ],
      "metadata": {
        "id": "xKKNz1orYNDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date, to_timestamp, date_diff"
      ],
      "metadata": {
        "id": "KMVT6lVUYMc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.withColumn('new_timestamp', to_timestamp(ratings.timestamp)).show()"
      ],
      "metadata": {
        "id": "EVQBTD0kYXQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace the unix timestamp with new timestamp:"
      ],
      "metadata": {
        "id": "LrkCuPYhYxpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratings.withColumn('timestamp', to_timestamp(ratings.timestamp))"
      ],
      "metadata": {
        "id": "b8uWzeuPYrjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.show()"
      ],
      "metadata": {
        "id": "hGr_8jtLY5Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the difference in minutes is more tedious, we'll need to convert the timestamps to unix timestamps (seconds since epoch), compute the difference, and divide by 60."
      ],
      "metadata": {
        "id": "yEQdF4vPZYCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taxi = taxi.withColumn('trip_duration', (taxi.dropoff_datetime.cast(\"long\") - taxi.pickup_datetime.cast(\"long\"))/60)"
      ],
      "metadata": {
        "id": "rH-rd1VrZJ03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.show(10)"
      ],
      "metadata": {
        "id": "tLciHlrXZ-Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User-Defined Functions (UDF)\n",
        "\n",
        "PySpark User-Defined Functions (UDFs) help you convert your Python code into a scalable version of itself. It is handy, but beware, as the performance is slower compared to PySpark functions."
      ],
      "metadata": {
        "id": "y-M54I7dadI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.functions import pandas_udf"
      ],
      "metadata": {
        "id": "jGlXlPczaxRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@pandas_udf('long')\n",
        "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
        "    # Simply plus one by using pandas Series.\n",
        "    return (series + 1.0).astype(float)"
      ],
      "metadata": {
        "id": "5Jqi_PDWa5Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.select(taxi.passenger_count, pandas_plus_one(taxi.passenger_count)).show()"
      ],
      "metadata": {
        "id": "kLgaPGtwa-3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataFrame Operations on Rows\n",
        "\n",
        "We will show the follwoing in this section:\n",
        "\n",
        "1.   Filtering Rows\n",
        "2. \t Get Distinct Rows\n",
        "3.   Sorting Rows"
      ],
      "metadata": {
        "id": "4XninFQBcE4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies.filter(movies.status == 'In Production').show()"
      ],
      "metadata": {
        "id": "sQIjymURcEas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.filter(ratings.rating > 4.5).show()"
      ],
      "metadata": {
        "id": "JF_42Wqlcu7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `&` and `|` for combining conditions as `and` and `or`:"
      ],
      "metadata": {
        "id": "zOQvZhSzc6Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.filter((ratings.rating < 1.5) | (ratings.rating > 4.5)).show()"
      ],
      "metadata": {
        "id": "uQCAnd65dBH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 1. Filter `movies` for `status` to be `In Production` and `vote_average` greater than 6.\n",
        "> 2. Filter `taxi` for `trip_duration` greater than 1 hour, `trip_distance` greater than 10 miles and `passenger_count` equal to and less than 2."
      ],
      "metadata": {
        "id": "YnY8muRUgzAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Filter movies for status 'In Production' and vote_average > 6\n",
        "# This will show movies that are still in production and have a vote_average greater than 6.\n",
        "# If this returns no records, it means there are no such movies in your dataset.\n",
        "movies.filter(\n",
        "    (movies.status == 'In Production') & (movies.vote_average > 6)\n",
        ").show()"
      ],
      "metadata": {
        "id": "Bvd8hGixFnvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Filter taxi for trip_duration > 1 hour, trip_distance > 10 miles, and passenger_count <= 2\n",
        "# First, create the trip_duration column (in minutes) using pickup and dropoff timestamps.\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "taxi = taxi.withColumn(\n",
        "    'trip_duration',\n",
        "    (col('dropoff_datetime').cast('long') - col('pickup_datetime').cast('long')) / 60\n",
        ")\n",
        "\n",
        "# Now filter for trips longer than 1 hour, distance > 10 miles, and 2 or fewer passengers.\n",
        "taxi.filter(\n",
        "    (col('trip_duration') > 60) &\n",
        "    (col('trip_distance') > 10) &\n",
        "    (col('passenger_count') <= 2)\n",
        ").show()"
      ],
      "metadata": {
        "id": "eTwtKxInFqd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.select('status').distinct().show()"
      ],
      "metadata": {
        "id": "4OudUbxfhwA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.orderBy('trip_duration').show()"
      ],
      "metadata": {
        "id": "IqdCao2Ah5Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.orderBy('trip_distance', ascending=False).show()"
      ],
      "metadata": {
        "id": "NlDn2cw8iCkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grouping Data"
      ],
      "metadata": {
        "id": "5nJKlUQDiWvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies.groupBy('status').count().show()"
      ],
      "metadata": {
        "id": "MQBnN-GEi4eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.groupBy('movieId').avg('rating').show()"
      ],
      "metadata": {
        "id": "qsxB74X6ibnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joining DataFrames"
      ],
      "metadata": {
        "id": "qVsyDwp_jdIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_avg_by_movie = ratings.groupBy('movieId').avg('rating')"
      ],
      "metadata": {
        "id": "_c9C3W12keQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_avg_by_movie.columns"
      ],
      "metadata": {
        "id": "-zmJq1wIkzF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.join(ratings_avg_by_movie, movies.id == ratings.movieId, 'inner').select('title', 'vote_average', 'avg(rating)').show()"
      ],
      "metadata": {
        "id": "8vPlsNt-jc1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spark SQL\n",
        "\n",
        "DataFrame and Spark SQL share the same execution engine so they can be interchangeably used seamlessly. For example, you can register the DataFrame as a table and run a SQL easily:"
      ],
      "metadata": {
        "id": "gZT7XuJzjozq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.createOrReplaceTempView(\"taxi\")\n",
        "spark.sql(\"SELECT count(*) from taxi\").show()"
      ],
      "metadata": {
        "id": "9sPiMKZSjtU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, UDFs can be registered and invoked in SQL out of the box:"
      ],
      "metadata": {
        "id": "gmCWYSSolXRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pandas_udf(\"double\")\n",
        "def div(s1: pd.Series, s2: pd.Series) -> pd.Series:\n",
        "    return s1 / s2"
      ],
      "metadata": {
        "id": "IniLwEVglQlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.udf.register(\"div\", div)\n",
        "spark.sql(\"SELECT trip_distance, trip_duration, div(trip_distance, trip_duration) AS speed FROM taxi\").show()"
      ],
      "metadata": {
        "id": "hJK58EWFlr1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi.selectExpr(\"div(trip_distance, trip_duration)\").show()"
      ],
      "metadata": {
        "id": "dt9E0TVANyz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas API on Spark\n",
        "\n",
        "Pandas API on Spark, previously known as Koalas, is an API that brings the power and flexibility of the pandas API to Apache Spark. It essentially bridges the gap between pandas and Spark by providing a pandas-like API while leveraging Spark's distributed computing capabilities. This makes it easier for pandas users to scale their data science workflows without major changes to their code."
      ],
      "metadata": {
        "id": "jDKF1z-9prFO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpPXr81QMdKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\""
      ],
      "metadata": {
        "id": "F0thTHMGaVKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show numpy"
      ],
      "metadata": {
        "id": "jAMEe9Rmaoy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyspark.pandas as ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoQvvgWeptlH",
        "outputId": "f8280bfd-331f-4e21-f0b0-776ba3b29605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a pandas-on-Spark Series and DataFrame:"
      ],
      "metadata": {
        "id": "gh8dew5Kmh4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = ps.Series([1, 3, 5, np.nan, 6, 8])"
      ],
      "metadata": {
        "id": "oCfXAvRQmfWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCt3VAZImnI0",
        "outputId": "117a6e97-5335-4095-8131-5210cd9bd808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    3.0\n",
              "2    5.0\n",
              "3    NaN\n",
              "4    6.0\n",
              "5    8.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psdf = ps.DataFrame(\n",
        "    {'a': [1, 2, 3, 4, 5, 6],\n",
        "     'b': [100, 200, 300, 400, 500, 600],\n",
        "     'c': [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"]},\n",
        "    index=[10, 20, 30, 40, 50, 60])"
      ],
      "metadata": {
        "id": "EIDMwEcymoIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "d_VJ75cymwLj",
        "outputId": "50f44e1b-e521-4e76-c7c6-d8e53626a666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    a    b      c\n",
              "10  1  100    one\n",
              "20  2  200    two\n",
              "30  3  300  three\n",
              "40  4  400   four\n",
              "50  5  500   five\n",
              "60  6  600    six"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2</td>\n",
              "      <td>200</td>\n",
              "      <td>two</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>3</td>\n",
              "      <td>300</td>\n",
              "      <td>three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>4</td>\n",
              "      <td>400</td>\n",
              "      <td>four</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>5</td>\n",
              "      <td>500</td>\n",
              "      <td>five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>6</td>\n",
              "      <td>600</td>\n",
              "      <td>six</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a pandas DataFrame by passing a numpy array, with a datetime index and labeled columns:"
      ],
      "metadata": {
        "id": "QU7CuTEtnGKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dates = pd.date_range('20130101', periods=6)"
      ],
      "metadata": {
        "id": "QlRrNZo6mw8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRvkdbhkm1jb",
        "outputId": "f8006159-3189-42d8-c0db-36279199a439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
              "               '2013-01-05', '2013-01-06'],\n",
              "              dtype='datetime64[ns]', freq='D')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
        "\n",
        "pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "d9FvgpQKm146",
        "outputId": "223f833b-174a-4e00-adfc-e44afd3caf2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   A         B         C         D\n",
              "2013-01-01 -1.448749 -0.560778 -0.504981  0.847135\n",
              "2013-01-02  0.495992 -1.298031 -1.734889 -0.407519\n",
              "2013-01-03 -0.616116 -1.523290 -1.334426 -0.555653\n",
              "2013-01-04  0.159137 -0.596122 -0.210986 -0.411034\n",
              "2013-01-05  0.923040 -1.154306  0.459133 -1.293728\n",
              "2013-01-06  0.688872 -0.108203  0.440477 -0.348606"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd176d4c-ad40-4238-ae70-850f1405a444\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>-1.448749</td>\n",
              "      <td>-0.560778</td>\n",
              "      <td>-0.504981</td>\n",
              "      <td>0.847135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>0.495992</td>\n",
              "      <td>-1.298031</td>\n",
              "      <td>-1.734889</td>\n",
              "      <td>-0.407519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>-0.616116</td>\n",
              "      <td>-1.523290</td>\n",
              "      <td>-1.334426</td>\n",
              "      <td>-0.555653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>0.159137</td>\n",
              "      <td>-0.596122</td>\n",
              "      <td>-0.210986</td>\n",
              "      <td>-0.411034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>0.923040</td>\n",
              "      <td>-1.154306</td>\n",
              "      <td>0.459133</td>\n",
              "      <td>-1.293728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-06</th>\n",
              "      <td>0.688872</td>\n",
              "      <td>-0.108203</td>\n",
              "      <td>0.440477</td>\n",
              "      <td>-0.348606</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd176d4c-ad40-4238-ae70-850f1405a444')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd176d4c-ad40-4238-ae70-850f1405a444 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd176d4c-ad40-4238-ae70-850f1405a444');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a50f4e26-2e84-4588-9e8a-e821139ba2d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a50f4e26-2e84-4588-9e8a-e821139ba2d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a50f4e26-2e84-4588-9e8a-e821139ba2d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7b24c00c-cd6a-42b0-b832-ff2583aebd14\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pdf')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7b24c00c-cd6a-42b0-b832-ff2583aebd14 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pdf');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pdf",
              "summary": "{\n  \"name\": \"pdf\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9021687838991883,\n        \"min\": -1.448749479852446,\n        \"max\": 0.9230403589635746,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -1.448749479852446,\n          0.49599167796463217,\n          0.6888723693139106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5369763100015615,\n        \"min\": -1.5232895898696857,\n        \"max\": -0.10820320991924201,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.5607779845578235,\n          -1.2980313708558442,\n          -0.10820320991924201\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9063141353088923,\n        \"min\": -1.7348890753656216,\n        \"max\": 0.45913327741036875,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.5049811262887104,\n          -1.7348890753656216,\n          0.44047692843557934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.688807730512032,\n        \"min\": -1.2937279531743677,\n        \"max\": 0.8471349077611032,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.8471349077611032,\n          -0.4075193278994716,\n          -0.34860580694591287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now convert this pandas DataFrame to a pandas-on-Spark DataFrame:"
      ],
      "metadata": {
        "id": "L_pNkyJlnIic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psdf = ps.from_pandas(pdf)"
      ],
      "metadata": {
        "id": "XUvOHyKUm4o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(psdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "UOhlJIDDnNcw",
        "outputId": "46ad3d42-2c42-49a2-ffcf-f477557f6449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.pandas.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.pandas.frame.DataFrame</b><br/>def __init__(data=None, index=None, columns=None, dtype=None, copy=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/pandas/frame.py</a>pandas-on-Spark DataFrame that corresponds to pandas DataFrame logically. This holds Spark\n",
              "DataFrame internally.\n",
              "\n",
              ":ivar _internal: an internal immutable Frame to manage metadata.\n",
              ":type _internal: InternalFrame\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : numpy ndarray (structured or homogeneous), dict, pandas DataFrame,\n",
              "    Spark DataFrame, pandas-on-Spark DataFrame or pandas-on-Spark Series.\n",
              "    Dict can contain Series, arrays, constants, or list-like objects\n",
              "index : Index or array-like\n",
              "    Index to use for the resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided\n",
              "columns : Index or array-like\n",
              "    Column labels to use for the resulting frame. Will default to\n",
              "    RangeIndex (0, 1, 2, ..., n) if no column labels are provided\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer\n",
              "copy : boolean, default False\n",
              "    Copy data from inputs. Only affects DataFrame / 2d ndarray input\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Since 3.4.0, it deals with `data` and `index` in this approach:\n",
              "    1, when `data` is a distributed dataset (Internal DataFrame/Spark DataFrame/\n",
              "    pandas-on-Spark DataFrame/pandas-on-Spark Series), it will first parallelize\n",
              "    the `index` if necessary, and then try to combine the `data` and `index`;\n",
              "    Note that if `data` and `index` doesn&#x27;t have the same anchor, then\n",
              "    `compute.ops_on_diff_frames` should be turned on;\n",
              "    2, when `data` is a local dataset (Pandas DataFrame/numpy ndarray/list/etc),\n",
              "    it will first collect the `index` to driver if necessary, and then apply\n",
              "    the `pandas.DataFrame(...)` creation internally;\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = ps.DataFrame(data=d, columns=[&#x27;col1&#x27;, &#x27;col2&#x27;])\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Constructing DataFrame from pandas DataFrame\n",
              "\n",
              "&gt;&gt;&gt; df = ps.DataFrame(pd.DataFrame(data=d, columns=[&#x27;col1&#x27;, &#x27;col2&#x27;]))\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = ps.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; ps.DataFrame(data=np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 0]]),\n",
              "...     columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;])\n",
              "   a  b  c  d  e\n",
              "0  1  2  3  4  5\n",
              "1  6  7  8  9  0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray with Pandas index:\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; import pandas as pd\n",
              "\n",
              "&gt;&gt;&gt; ps.DataFrame(data=np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 0]]),\n",
              "...     index=pd.Index([1, 4]), columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;])\n",
              "   a  b  c  d  e\n",
              "1  1  2  3  4  5\n",
              "4  6  7  8  9  0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray with pandas-on-Spark index:\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; import pandas as pd\n",
              "&gt;&gt;&gt; ps.DataFrame(data=np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 0]]),\n",
              "...     index=ps.Index([1, 4]), columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;])\n",
              "   a  b  c  d  e\n",
              "1  1  2  3  4  5\n",
              "4  6  7  8  9  0\n",
              "\n",
              "Constructing DataFrame from Pandas DataFrame with Pandas index:\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; import pandas as pd\n",
              "&gt;&gt;&gt; pdf = pd.DataFrame(data=np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 0]]),\n",
              "...     columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;])\n",
              "&gt;&gt;&gt; ps.DataFrame(data=pdf, index=pd.Index([1, 4]))\n",
              "     a    b    c    d    e\n",
              "1  6.0  7.0  8.0  9.0  0.0\n",
              "4  NaN  NaN  NaN  NaN  NaN\n",
              "\n",
              "Constructing DataFrame from Pandas DataFrame with pandas-on-Spark index:\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; import pandas as pd\n",
              "&gt;&gt;&gt; pdf = pd.DataFrame(data=np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 0]]),\n",
              "...     columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;])\n",
              "&gt;&gt;&gt; ps.DataFrame(data=pdf, index=ps.Index([1, 4]))\n",
              "     a    b    c    d    e\n",
              "1  6.0  7.0  8.0  9.0  0.0\n",
              "4  NaN  NaN  NaN  NaN  NaN\n",
              "\n",
              "Constructing DataFrame from Spark DataFrame with Pandas index:\n",
              "\n",
              "&gt;&gt;&gt; import pandas as pd\n",
              "&gt;&gt;&gt; sdf = spark.createDataFrame([(&quot;Data&quot;, 1), (&quot;Bricks&quot;, 2)], [&quot;x&quot;, &quot;y&quot;])\n",
              "&gt;&gt;&gt; ps.DataFrame(data=sdf, index=pd.Index([0, 1, 2]))\n",
              "Traceback (most recent call last):\n",
              "  ...\n",
              "ValueError: Cannot combine the series or dataframe...&#x27;compute.ops_on_diff_frames&#x27; option.\n",
              "\n",
              "Enable &#x27;compute.ops_on_diff_frames&#x27; to combine SparkDataFrame and Pandas index\n",
              "\n",
              "&gt;&gt;&gt; with ps.option_context(&quot;compute.ops_on_diff_frames&quot;, True):\n",
              "...     ps.DataFrame(data=sdf, index=pd.Index([0, 1, 2]))\n",
              "        x    y\n",
              "0    Data  1.0\n",
              "1  Bricks  2.0\n",
              "2    None  NaN\n",
              "\n",
              "Constructing DataFrame from Spark DataFrame with pandas-on-Spark index:\n",
              "\n",
              "&gt;&gt;&gt; import pandas as pd\n",
              "&gt;&gt;&gt; sdf = spark.createDataFrame([(&quot;Data&quot;, 1), (&quot;Bricks&quot;, 2)], [&quot;x&quot;, &quot;y&quot;])\n",
              "&gt;&gt;&gt; ps.DataFrame(data=sdf, index=ps.Index([0, 1, 2]))\n",
              "Traceback (most recent call last):\n",
              "  ...\n",
              "ValueError: Cannot combine the series or dataframe...&#x27;compute.ops_on_diff_frames&#x27; option.\n",
              "\n",
              "Enable &#x27;compute.ops_on_diff_frames&#x27; to combine Spark DataFrame and pandas-on-Spark index\n",
              "\n",
              "&gt;&gt;&gt; with ps.option_context(&quot;compute.ops_on_diff_frames&quot;, True):\n",
              "...     ps.DataFrame(data=sdf, index=ps.Index([0, 1, 2]))\n",
              "        x    y\n",
              "0    Data  1.0\n",
              "1  Bricks  2.0\n",
              "2    None  NaN</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 369);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks and behaves the same as a pandas DataFrame."
      ],
      "metadata": {
        "id": "ufWaiTvlnQg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psdf"
      ],
      "metadata": {
        "id": "d0Ecf517nOGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Spark DataFrame from pandas DataFrame:"
      ],
      "metadata": {
        "id": "WNecpN-8nV5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf = spark.createDataFrame(pdf)"
      ],
      "metadata": {
        "id": "HQ1mES1dnSov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.show()"
      ],
      "metadata": {
        "id": "lvk1b0M-oZIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, it is possible to create a pandas-on-Spark DataFrame from Spark DataFrame easily."
      ],
      "metadata": {
        "id": "QQEPMBU8oYq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psdf = sdf.pandas_api()\n",
        "\n",
        "psdf"
      ],
      "metadata": {
        "id": "jeJBEtPtoXVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psdf.plot()"
      ],
      "metadata": {
        "id": "JTfOr5aJohVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf.plot()"
      ],
      "metadata": {
        "id": "_POpNtaDo7Ad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}